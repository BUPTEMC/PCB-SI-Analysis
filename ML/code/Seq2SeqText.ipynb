{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n",
      "sys.version_info(major=3, minor=7, micro=6, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.3\n",
      "numpy 1.18.1\n",
      "pandas 1.0.1\n",
      "sklearn 0.22.1\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 预处理\n",
    "# 2. 搭建模型\n",
    "# 2.1 encoder\n",
    "# 2.2 attention\n",
    "# 2.3 decoder\n",
    "# 2.4 loss & optimizer\n",
    "# 2.5 train\n",
    "# 3. evaluation\n",
    "# 3.1 给序列，出结果\n",
    "# 3.2 可视化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Then what？\n",
      "¿Entonces que?\n"
     ]
    }
   ],
   "source": [
    "## 西班牙语预处理, 取消注音\n",
    "path = \"../data_span_en/spa.txt\"\n",
    "\n",
    "import unicodedata\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "en_sentence = \"Then what？\"\n",
    "sp_sentence = \"¿Entonces qué?\"\n",
    "\n",
    "print(unicode_to_ascii(en_sentence))\n",
    "print(unicode_to_ascii(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> ¿ entonces que ? <end>\n"
     ]
    }
   ],
   "source": [
    "## 处理句子\n",
    "import re\n",
    "def preprocess_sentence(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    # 标点符号前后加空格\n",
    "    s = re.sub(r\"([?.!,¿])\", r\" \\1 \", s)\n",
    "    s = re.sub(r'[\" \"]+', \" \", s)\n",
    "    # 除了标点和单词全变成空格\n",
    "    s = re.sub(r'[^a-zA-Z?.!,¿]', \" \", s)\n",
    "    # 去掉前后空格\n",
    "    s = s.rstrip().strip()\n",
    "    s = '<start> ' + s + ' <end>'\n",
    "    return s\n",
    "\n",
    "print(preprocess_sentence(sp_sentence))\n",
    "# print(preprocess_sentence(en_sentence))\n",
    "# print(preprocess_sentence(sp_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> if you want to sound like a native speaker , you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo . <end>\n",
      "<start> si quieres sonar como un hablante nativo , debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un musico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado . <end>\n"
     ]
    }
   ],
   "source": [
    "def parse_data(filename):\n",
    "    lines = open(filename, encoding='UTF-8').read().strip().split('\\n')\n",
    "    sentence_pairs = [line.split('\\t') for line in lines]\n",
    "    preprocessed_sentence_pairs = [\n",
    "        (preprocess_sentence(en), preprocess_sentence(sp)) for en, sp in sentence_pairs]\n",
    "#     print(preprocessed_sentence_pairs)\n",
    "    return zip(*preprocessed_sentence_pairs)\n",
    "\n",
    "en_dataset, sp_dataset = parse_data(path)\n",
    "print(en_dataset[-1])\n",
    "print(sp_dataset[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 5) (2, 4, 6)\n"
     ]
    }
   ],
   "source": [
    "a = [(1, 2), (3, 4), (5, 6)]\n",
    "c,d = zip(*a)\n",
    "print(c,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 16)\n",
      "16 11\n"
     ]
    }
   ],
   "source": [
    "# sentence embedding --> 将句子转化为tensor\n",
    "\n",
    "def tokenizer(lang):\n",
    "    lang_tokenizer = keras.preprocessing.text.Tokenizer(num_words=None, filters='',split=' ')\n",
    "    lang_tokenizer.fit_on_texts(lang)\n",
    "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
    "    tensor = keras.preprocessing.sequence.pad_sequences(tensor, \n",
    "                                                        padding='post')\n",
    "    return tensor, lang_tokenizer\n",
    "\n",
    "# shape: [30000, max_sentences_length]\n",
    "input_tensor, input_tokenizer = tokenizer(sp_dataset[0: 30000])\n",
    "output_tensor, output_tokenizer = tokenizer(en_dataset[0: 30000])\n",
    "\n",
    "print(input_tensor.shape)\n",
    "\n",
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "max_length_input  = max_length(input_tensor)\n",
    "max_length_output  = max_length(output_tensor)\n",
    "print(max_length_input, max_length_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   1   59   18 ...    0    0    0]\n",
      " [   1   47  307 ...    0    0    0]\n",
      " [   1  207   11 ...    0    0    0]\n",
      " ...\n",
      " [   1 2329   56 ...    0    0    0]\n",
      " [   1 1073   34 ...    0    0    0]\n",
      " [   1   94   16 ...    0    0    0]]\n",
      "训练集样本数： 24000\n",
      "测试集样本数： 6000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 20%作为测试集\n",
    "input_train, input_eval, output_train, output_eval = train_test_split(input_tensor, output_tensor, test_size=0.2)\n",
    "print(input_train[0:100])\n",
    "print(\"训练集样本数：\", len(input_train))\n",
    "print(\"测试集样本数：\", len(input_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ---> <start>\n",
      "59 ---> tomas\n",
      "18 ---> lo\n",
      "769 ---> intenta\n",
      "3 ---> .\n",
      "2 ---> <end>\n",
      "\n",
      "1 ---> <start>\n",
      "5 ---> tom\n",
      "1934 ---> tries\n",
      "3 ---> .\n",
      "2 ---> <end>\n"
     ]
    }
   ],
   "source": [
    "def convert(example, tokenizer):\n",
    "    for t in example:\n",
    "        if t != 0:\n",
    "            print('%d ---> %s' % (t, tokenizer.index_word[t]))\n",
    "            \n",
    "convert(input_train[0], input_tokenizer)\n",
    "print()\n",
    "convert(output_train[0], output_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(input_tensor, output_tensor,\n",
    "                 batch_size, epochs, shuffle):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(30000)\n",
    "        dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder=True)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 20\n",
    "\n",
    "train_dataset = make_dataset(input_train, output_train, batch_size, epochs, True)\n",
    "eval_dataset = make_dataset(input_eval, output_eval, batch_size, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 16)\n",
      "(64, 11)\n"
     ]
    }
   ],
   "source": [
    "for x,y in train_dataset.take(1):\n",
    "    print(x.shape)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_units = 256\n",
    "# RNN Encoder 的单元数量, 最后输出1024个值\n",
    "encoding_units = 1024\n",
    "# RNN Decoder 的单元数量，最后输出1024个值\n",
    "decoding_units = 1024\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "output_vocab_size = len(output_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_output shape: (64, 16, 1024)\n",
      "sample_hidden shape: (64, 1024)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_units, encoding_units, batch_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
    "        \n",
    "        self.gru = keras.layers.GRU(self.encoding_units,\n",
    "                                    return_sequences = True,\n",
    "                                    return_state = True,\n",
    "                                    recurrent_initializer = 'glorot_uniform')\n",
    "    \n",
    "    def call(self, input_sentence, hidden):\n",
    "        # before embedding: x.shape = (batch_size, length)\n",
    "        # after embedding: s.shape = (batch_size, length, embedding_units)\n",
    "        x = self.embedding(input_sentence)\n",
    "#         print(x.shape)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoding_units))\n",
    "    \n",
    "encoder = Encoder(input_vocab_size, embedding_units, encoding_units, batch_size)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(x, sample_hidden)\n",
    "\n",
    "print(\"sample_output shape:\", sample_output.shape)\n",
    "print(\"sample_hidden shape:\", sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_results shape: (64, 1024)\n",
      "atteion_weigths shape: (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(keras.Model):\n",
    "    def __init__(self, attention_units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = keras.layers.Dense(attention_units)\n",
    "        self.W2 = keras.layers.Dense(attention_units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden shape: (batch_size, encoding_units)\n",
    "        # encoder_output shape: (batch_size, length, encoding_units)\n",
    "        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden, 1)\n",
    "        \n",
    "        # before V: (batch_size, length, attention_units)\n",
    "#         print( tf.nn.tanh(\n",
    "#                 self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)).shape)\n",
    "        # after V: (batch_size, length, 1)\n",
    "        score = self.V(\n",
    "            tf.nn.tanh(\n",
    "                self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n",
    "        \n",
    "        # shape: (batch_size, length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        \n",
    "        # shape: (batch_size, length, encoding_units)\n",
    "        context_vector = attention_weights * encoder_outputs\n",
    "        \n",
    "        # shape: (batch_size, encoding_units)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "attention_model = BahdanauAttention(10)\n",
    "attention_results, attention_weights = attention_model(sample_hidden, sample_output)\n",
    "print(\"attention_results shape:\", attention_results.shape)\n",
    "print(\"atteion_weigths shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 5)\n",
      "tf.Tensor(\n",
      "[[1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]\n",
      " [1. 1.]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.ones((4,1,2))\n",
    "b = tf.ones((4,1,3))\n",
    "c = tf.concat([a,b],axis = -1)\n",
    "print(c.shape)\n",
    "d = tf.reduce_sum(a, axis=1)\n",
    "print(d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output shape: (64, 4935)\n",
      "decoder_hidden shape: (64, 1024)\n",
      "decoder_attention_weights shape: (64, 16, 1)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_units, decoding_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        self.embedding = keras.layers.Embedding(vocab_size, embedding_units)\n",
    "        self.gru = keras.layers.GRU(self.decoding_units,\n",
    "                                    return_sequences = True,\n",
    "                                    return_state = True,\n",
    "                                    recurrent_initializer = 'glorot_uniform')\n",
    "        self.fc = keras.layers.Dense(vocab_size)\n",
    "        self.attention = BahdanauAttention(self.decoding_units)\n",
    "        \n",
    "    def call(self, input_word, hidden, encoding_outputs):\n",
    "        # context_vector shape: (batch_size, encoding_units)\n",
    "        context_vector, attention_weights = self.attention(hidden, encoding_outputs)\n",
    "        \n",
    "        x = input_word\n",
    "        # before embedding: x.shape: (batch_size, 1)\n",
    "        # after embedding: x.shape(batch_size, 1, embedding_units)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # context_vector shape: (batch_size, 1, encoding_units)\n",
    "        context_vector = tf.expand_dims(context_vector, 1)\n",
    "        \n",
    "        # combined_x shape: (batch_size, 1, encoding_units + embedding_units)\n",
    "        combined_x = tf.concat([context_vector, x], axis = -1)\n",
    "        \n",
    "        # output shape: (batch_size, 1, decoding_units)\n",
    "        # state shaoe: (batch_size, decoding_units)\n",
    "        output, state = self.gru(combined_x)\n",
    "        \n",
    "        # output shape: (batch_size, decoding_units)\n",
    "        output = tf.reshape(output, shape = (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape: (batch_size, vocab_size)\n",
    "        output = self.fc(output)\n",
    "        \n",
    "        return output, state, attention_weights\n",
    "    \n",
    "\n",
    "decoder = Decoder(output_vocab_size, embedding_units, decoding_units, batch_size)\n",
    "outputs = decoder(tf.random.uniform((batch_size, 1)), sample_hidden, sample_output)\n",
    "\n",
    "decoder_output, decoder_hidden, decoder_aw = outputs\n",
    "\n",
    "print(\"decoder_output shape:\", decoder_output.shape)\n",
    "print(\"decoder_hidden shape:\", decoder_hidden.shape)\n",
    "print(\"decoder_attention_weights shape:\", decoder_aw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "# 这里reduction设置成none是为了将sentence中padding的部分做去除操作，先不聚合\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # 补长padding的部分设置成0，不参与loss的计算\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def train_step(inp, targ, encoding_hidden):\n",
    "    loss = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoding_outputs, encoding_hidden = encoder(inp, encoding_hidden)\n",
    "        \n",
    "        decoding_hidden = encoding_hidden\n",
    "        \n",
    "        # e.g. <start> I am here <end>\n",
    "        # 1. <start> -> I\n",
    "        # 2. I -> am\n",
    "        # 3. am -> here\n",
    "        # 4. here -> <end>\n",
    "        \n",
    "        for t in range(0, targ.shape[1] - 1):\n",
    "            # decoding_input shape: (batch_size, 1)\n",
    "            decoding_input = tf.expand_dims(targ[:, t], 1)\n",
    "            \n",
    "            predictions, decoder_hidden, _ = decoder(decoding_input, decoding_hidden, encoding_outputs)\n",
    "            print(predictions.shape)\n",
    "            print(targ[:, t+1].shape)\n",
    "            print(targ[:, t+1])\n",
    "            loss += loss_function(targ[:, t+1], predictions)\n",
    "    \n",
    "    batch_loss = loss / int(targ.shape[0])\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  20    4    4    4   21   25   10   14   32   14    4  562  120   29\n",
      " 2015    4   42 4809   27    6   46   56    6   32    4  125   22    6\n",
      "   21    5    6    4  124    4   20    4   10    4   28 1582    6    4\n",
      "   86    4    6    4   24   20   28   94    8   71    6    4    6   10\n",
      "   28   52   10   27   16   27    5    4], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  11   38  210   47 2963    4   11   11   11  870  100   13  142 1491\n",
      "   49  133    6    8 1001   25   11   40   23  223   65   20   53   23\n",
      "  168  401   63 4118   31   95  113   26   11   65   92   13   29   29\n",
      " 2024   25   23   26   28   11   23   19   10   23   23   25   23  164\n",
      "  230   11    8   11   23    8    8   65], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  32   40   43  140 1128   72  204   33   13   67   12 1820   13    3\n",
      "   90   20   72  517   41 2202   64 1541   67  986 1649   44   33 1698\n",
      "    8 1072   15   21  104   20    8  488   58  250  106 1416   15    9\n",
      "    3   12  147  483  405    9 1564    3   97    6  484  161   21   12\n",
      "   81   13  623 1359 2465 1090  626  238], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[   4 1957    3  162 2067   20   15 1387  430   61   86    3 1243    2\n",
      "   12  529   68    3    3   44  241    3 4039   37    5    3   37    3\n",
      "  393    3  281 2332 1059    3  393   54    3  392  152   49   36  303\n",
      "    2  477    3   57    7 1846   59    2    6  129   17 2212  469 1011\n",
      "    3  146   13    3    3    9    3   10], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  47    3    2    3    3   84  846    3    7  115    6    2    3    0\n",
      "   10    3  449    2    2   68    3    2    3    2    3    2    2    2\n",
      "    3    2    3    3    7    2    3    6    2    3    3   56   91  115\n",
      "    0   41    2    3    2 3768 1597    0   63    7    3    3    3    3\n",
      "    2  134 1181    2    2  427    2  580], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[3 2 0 2 2 7 3 2 2 3 3 0 2 0 7 2 7 0 0 3 2 0 2 0 2 0 0 0 2 0 2 2 2 0 2 3 0\n",
      " 2 2 3 3 3 0 3 0 2 0 3 3 0 7 2 2 2 2 2 0 7 3 0 0 3 0 3], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[2 0 0 0 0 2 2 0 0 2 2 0 0 0 2 0 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0\n",
      " 0 0 2 2 2 0 2 0 0 0 2 2 0 2 0 0 0 0 0 0 2 2 0 0 2 0 2], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "Epoch 1 Batch 0 Loss  0.5625\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  96   14  584   28    5   42  351   20   19    4   27   46   62    6\n",
      "    4  124   10    4   16   20   22    5    6    4    4    4   13    5\n",
      "   29    4   20   70  111    6  455    4 1702   28    4   27   88   70\n",
      "  195   71   52  177  181    4   30    5  486    4    4  189   20   36\n",
      "   31  396    4   30    4   27    4   62], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[   4   11   49   38  121   28   54   11    8   25  289   11    4  100\n",
      "  164   14   11   18   65  678    6    8  398   18  133   75 1241    8\n",
      "  214   18   11   22  170   23    6   29   10   25  439  124   55    9\n",
      "    8   24  169   52   42   18   12 3491  192   62   26   51   38   89\n",
      "  104   11   18   12   30   76   18    4], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[ 805   33  280 1300  408   53  865  204   21 1152   41  369 2671   12\n",
      "   12   43   97  261  160   17   29 2029  810    9  403  338 2588  130\n",
      "    3  253   69   31  144   21   49   15    3  541   61  133   19  702\n",
      "  589   13    4    4    6  336  345    3    7  146  483   70   22   58\n",
      "    8  182 4394 2305   12   41   34  184], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[   6   13   44    3  215  110   17   15 2985   10    3   54    6 1074\n",
      " 1498   17   15  109  488  193    9    3    3 2054    3   13    3  722\n",
      "    2    3   15  278   17 1038   21  120    2    3  206  327  713    3\n",
      "    3 3112 1730   22   36  342   41    2    2   39   33 1031    3    3\n",
      "   48   37   44   13  574  241  182    7], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[   7 1007    9    2    3    7    3  136    3    3    2    9    7   10\n",
      "    3    7   36  110    3    3  735    2    2    3    2 4126    2    3\n",
      "    0    2   43    3    3    3  206   89    0    2    3    3    3    3\n",
      "    2    7    7   10   89    3    3    0    0    3    3    3    2    2\n",
      "  374    2    6 1709    3    3    3    2], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[   2    3  647    0    2    2    2    3    2    2    0 1319    2    3\n",
      "    2    2    3    3    2    2    7    0    0    2    0    3    0    2\n",
      "    0    0    3    2    2    2    3    3    0    0    2    2    2    3\n",
      "    0    2    2    3    7    2    2    0    0    2    2    2    0    0\n",
      "    3    0    3    3    2    2    2    0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 2 3 0 0 0 0 2 0 0 0 3 0 2 0 0 2 2 0 0 2 0 0 0 0 2 0 0 0 0 2 0 0 0 2 2 0\n",
      " 0 0 0 0 2 0 0 0 2 2 0 0 0 0 0 0 0 0 0 2 0 2 2 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[ 10   4   4  14  13  60   6  46 245  94  19   8  13  10  24 188 156  22\n",
      "  14   5  27  20  10 441  25   4  14   8 497  53  13  16   4  27   4   5\n",
      "   4   4   4  82  10  14  30   4 992  10   4   5  28  71   5   5  46  36\n",
      "   5   4   5  19  10 156   4  14  25  27], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[ 118   35 1036  305 3482  257   24   17  781    9    8    5 1876  117\n",
      "    6  833  196    6  118 3817  118   11   11   27    6   75  952   19\n",
      "   13   55  838   25   53 2367  337  570   75   65   18   24   26  476\n",
      "   12   62   90   26  118   26   23   11   26    8   11  939   51   35\n",
      "  251   84   11  323   18    8   16   51], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  48 4109    9   67  240    5   13   33    3   88 2571  155   24   17\n",
      "    7  604   49   47   91    9   20  198    9    8  202   22   15  150\n",
      "   83  208    8   36  144   68   59   55  156  238 2706    6    9   55\n",
      "  450   34   12    9   49 1369   69   21  612  485   34   31  160  528\n",
      "   17    8   78   55  633  261 1368    9], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[ 109 2971  146  265    3    7  278   49    2   55    3    7  297  130\n",
      "    2    3   56   15   89 2045  196    3   69  217   68   21   13  935\n",
      "    3 1437  155    3  731  774  262   45  140   20   74  193  523   17\n",
      "   21    9 2888  977   78    3    3 3667   55    3 1286  744  148    9\n",
      "   15  866 1144   89   37 4074   10  231], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[   3    3  168    3    2    2    3   56    0   19    2    2    3  294\n",
      "    0    2    3  112    3    3    3    2  595    3    7  278 2006    7\n",
      "    2  654    3    2    3    3    5    3  383    9    3    7  265    3\n",
      " 1048  563    3    3    3    2    2    7   17    2    5    3    3  153\n",
      "  318    3    3    3    2    3    7  726], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  2   2   3   2   0   0   2   3   0   3   0   0   2   3   0   0   2   7\n",
      "   2   2   2   0   3   2   2   3   3   2   0   3   2   0   2   2   3   2\n",
      "   3 153   2   2   3   2   3   3   2   2   2   0   0   2   3   0   3   2\n",
      "   2   3   3   2   2   2   0   2   2   3], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 2 0 0 0 0 2 0 2 0 0 0 2 0 0 0 2 0 0 0 0 2 0 0 2 2 0 0 2 0 0 0 0 2 0 2\n",
      " 3 0 0 2 0 2 2 0 0 0 0 0 0 2 0 2 0 0 2 2 0 0 0 0 0 0 2], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  4   6  21   6  52   5  60   4  27   4  75  14   5   4 178   5  14  20\n",
      "   6   4   4 318  13  10  46   5  52  60  42  19   4 157   4  16   4  58\n",
      "  60   4  32 189  13  14  14   5   4   5   5  24   5   6   5   4  42   4\n",
      "  94   4  57  28   4   4  29   4  30   4], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  18   43  394   92   11  137  621   62  276  135    6  508    8  164\n",
      " 1950   11   51  552   23  336  114  103  104   11   11 1914   42  180\n",
      "    6  113   35 1224   30   63  239  400  180   18   42    8 3964   76\n",
      "   26 1456  699    8  118    6    8   24   75   25    6   26    5   25\n",
      "   11   43   62   18    6   29   12   38], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  34   60  145   33   13 1030    5   48  667   31   36   15   48   12\n",
      "  949 3238    9    3 1047  512   10    3    8  209  496   45    6   19\n",
      "  304    8  588    3   12  140   10   50    9  193    6    9  145  170\n",
      "  373 3132    5    9   74   33  152   48   53  127  102 1044   11  556\n",
      "   66   52   44 1398 1229  160  686  268], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[ 340    4  172    9 1622   74    7 1175    3  610    7  309 1316   48\n",
      "    3    3  545    2    3   10   11    2  571    9    9  115  208    7\n",
      "   21  263    3    2  304 1573   11    3  207    3  671  394   74    3\n",
      "  138    3    3 3394   15   57  131  296  299  139    9    3  591   13\n",
      "   84   15  729    3   13   15  119   15], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[   3   62    3 1433    7    3    2    3    2    3    2    3    3  633\n",
      "    2    2  471    0    2    3   78    0    3 4155 1244    3  369    2\n",
      "  595    3    2    0 1473    3   34    2    7    2    7    3    3    2\n",
      "    3    2    2    3  112    7    3    3    3    3 2946    2    3 2903\n",
      "  151  246   58    2  104  653   81 4724], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[  2   3   2   3   2   2   0   2   0   2   0   2   2   3   0   0   3   0\n",
      "   0   2 167   0   2   3   3   2   7   0   7   2   0   0   3   2 172   0\n",
      "   2   0   2   2   2   0   2   0   0   2   3   2   2   2   2   2   7   0\n",
      "   2   3   3   3   3   0   7   3   3   3], shape=(64,), dtype=int32)\n",
      "(64, 4935)\n",
      "(64,)\n",
      "tf.Tensor(\n",
      "[0 2 0 2 0 0 0 0 0 0 0 0 0 2 0 0 2 0 0 0 3 0 0 2 2 0 2 0 2 0 0 0 2 0 3 0 0\n",
      " 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 2 0 0 2 2 2 2 0 2 2 2 2], shape=(64,), dtype=int32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-6e0fa5588467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     for (batch, (inp, targ)) in enumerate(\n\u001b[1;32m     10\u001b[0m         train_dataset.take(steps_per_epoch)):\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-1550a26cd938>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, targ, encoding_hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mdecoding_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoding_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoding_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-17fe67df8fd9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, input_word, hidden, encoding_outputs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# output shape: (batch_size, 1, decoding_units)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# state shaoe: (batch_size, decoding_units)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# output shape: (batch_size, decoding_units)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m    311\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;31m# GRU does not support constants. Ignore it during process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(self, inputs, initial_state, constants)\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m       \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_initial_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36mget_initial_state\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_major\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mget_initial_state_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m    977\u001b[0m       \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m       \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m       shrink_axis_mask=shrink_axis_mask)\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m   \u001b[0mparent_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mstrided_slice\u001b[0;34m(input, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, name)\u001b[0m\n\u001b[1;32m  10354\u001b[0m         \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"begin_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbegin_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10355\u001b[0m         \u001b[0;34m\"ellipsis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mellipsis_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"new_axis_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_axis_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10356\u001b[0;31m         \"shrink_axis_mask\", shrink_axis_mask)\n\u001b[0m\u001b[1;32m  10357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10358\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(input_tensor) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    encoding_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    for (batch, (inp, targ)) in enumerate(\n",
    "        train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, encoding_hidden)\n",
    "        total_loss += batch_loss\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {: .4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    \n",
    "    print('Time take for 1 epoch {} sec \\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_sentence):\n",
    "    attention_matrix = np.zeros((max_length_output, max_length_input))\n",
    "    input_sentence = preprocess_sentence(input_sentence)\n",
    "    inputs = [input_tokenizer.word_index[token] for token in input_sentence.split(' ')]\n",
    "#     print(inputs)\n",
    "    inputs = keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_input, padding = 'post')\n",
    "#     print(inputs)\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    results = ''\n",
    "    encoding_hidden = tf.zeros(shape=(1, encoding_units))\n",
    "    encoding_outputs, encoding_hidden = encoder(inputs, encoding_hidden)\n",
    "    decoder_hidden = encoding_hidden\n",
    "    \n",
    "    # decoding_input shape: (1, 1)\n",
    "    decoding_input = tf.expand_dims([output_tokenizer.word_index['<start>']], 0)\n",
    "    \n",
    "    for t in range(max_length_output):\n",
    "        # attention_weights.shape: (batch_size, input_length, 1) == (1, input_length, 1)\n",
    "        predictions, decoding_hidden, attention_weights = decoder(decoding_input, decoder_hidden, encoding_outputs)\n",
    "        \n",
    "        # attention_weights.shape: (16,)\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        \n",
    "        attention_matrix[t] = attention_weights.numpy()\n",
    "        \n",
    "        # predicitons shape: (batch_size, vocab_size) (1, 4935)\n",
    "        prediction_id = tf.argmax(predictions[0]).numpy()\n",
    "        results += output_tokenizer.index_word[prediction_id] + ' '\n",
    "        if(output_tokenizer.index_word[prediction_id] == '<end>'):\n",
    "            return results, input_sentence, attention_matrix\n",
    "        \n",
    "        decoding_input = tf.expand_dims([prediction_id], 0)\n",
    "    return results, input_sentence, attention_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention_matrix, input_sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention_matrix, cmap='viridis')\n",
    "    \n",
    "    font_dict = {'fontsize': 14}\n",
    "    ax.set_xticklabels(['']+input_sentence, fontdict = font_dict, rotation = 90)\n",
    "    ax.set_yticklabels(['']+predicted_sentence, fontdict = font_dict)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_sentence):\n",
    "    results, input_sentece, attention_matrix = evaluate(input_sentence)\n",
    "    print(\"Input: %s\" % (input_sentece))\n",
    "    print(\"Prediceted translation: %s\" % (results))\n",
    "    \n",
    "    attention_matrix = attention_matrix[:len(results.split(' ')),\n",
    "                                        :len(input_sentece.split(' '))]\n",
    "    \n",
    "    plot_attention(attention_matrix, input_sentece.split(' '), results.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> ¿ entonces que ? <end>\n",
      "Prediceted translation: what ? <end> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# en_sentence = \"Then what？\"\n",
    "sp_sentence = \"¿Entonces qué?\"\n",
    "translate(sp_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
