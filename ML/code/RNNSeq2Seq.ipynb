{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. preprocessing data\n",
    "# 2. build model\n",
    "# 2.1 encoder\n",
    "# 2.2 attention\n",
    "# 2.3 decoder\n",
    "# 3. evaluation\n",
    "# 3.1 give data, return result\n",
    "# 3.2 visualize\n",
    "\n",
    "path = \"../output/demo2.csv\"\n",
    "dir_path = \"../output/\"\n",
    "encoding_units = 1024\n",
    "batch_size = 1\n",
    "classify = {0: 'ok', 1: 'crosstalked'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv(path, header=None)\n",
    "b = a.values\n",
    "# print(type(b))\n",
    "c = tf.convert_to_tensor(b[:, :-1])\n",
    "d = tf.convert_to_tensor(b[:, -1:])\n",
    "print(c.shape[0])\n",
    "# print(d)\n",
    "x = tf.fill((3,219), -999)\n",
    "# x = tf.cast(x, dtype=tf.double)\n",
    "# y = tf.concat([c, x], axis = 0)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/memoforward/Documents/Lab/EMCManagement/code/pythonCode/ML/output/mainboard.csv\n",
      "/Users/memoforward/Documents/Lab/EMCManagement/code/pythonCode/ML/output/mt18vddt6472ag-265c4.csv\n",
      "/Users/memoforward/Documents/Lab/EMCManagement/code/pythonCode/ML/output/SampleAD-01.csv\n",
      "/Users/memoforward/Documents/Lab/EMCManagement/code/pythonCode/ML/output/SampleAD-02.csv\n",
      "/Users/memoforward/Documents/Lab/EMCManagement/code/pythonCode/ML/output/AD8367_VGA.csv\n",
      "/Users/memoforward/Documents/Lab/EMCManagement/code/pythonCode/ML/output/demo2.csv\n"
     ]
    }
   ],
   "source": [
    "# print(os.path.abspath(dir_path))\n",
    "for filename in os.listdir(dir_path):\n",
    "    abs_dir_path = os.path.abspath(dir_path)\n",
    "#     print(filename)\n",
    "    if filename[-3:] == \"csv\":\n",
    "        file_path = abs_dir_path + '/'+ filename\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def prase_data(file_dir):\n",
    "    \"\"\"\n",
    "    @file_dir: 数据所在文件夹\n",
    "    \"\"\"\n",
    "    maxlen = 0\n",
    "    embedding_units = 0\n",
    "    data_list = []\n",
    "    count = 0\n",
    "    flag = True\n",
    "    # 1. 读取文件夹下所有的文件，并获取最大的PCB序列长度\n",
    "    for filename in os.listdir(dir_path):\n",
    "        abs_dir_path = os.path.abspath(dir_path)\n",
    "        if filename[-3:] == \"csv\":\n",
    "            file_path = abs_dir_path + '/' + filename\n",
    "            pd_data = pd.read_csv(file_path, header=None)\n",
    "            maxlen = max(pd_data.values.shape[0], maxlen)\n",
    "            if embedding_units == 0:\n",
    "                embedding_units = pd_data.values.shape[1] - 1 \n",
    "            elif embedding_units != pd_data.values.shape[1] - 1:\n",
    "                print(\"数据有问题，embbedding 维度不一致!\")\n",
    "                return None,None,None\n",
    "            data_list.append(pd_data)\n",
    "    print(\"max_len:\", maxlen)\n",
    "        \n",
    "    # 2. 读取数据，并获得训练的tensor，返回input_tensor和output_tensor\n",
    "    for _data in data_list:\n",
    "        # 2.1 读取数据\n",
    "        # TODO: 在这里添加数据的预处理,比如归一化什么的\n",
    "        data = tf.convert_to_tensor(_data.values)\n",
    "        data = tf.cast(data, dtype=tf.float32)\n",
    "        # 2.2 拓展PCB序列长度到同一个维度\n",
    "        padding_len = maxlen - data.shape[0]\n",
    "        if padding_len > 0:\n",
    "            padding_value = tf.fill((padding_len, data.shape[1]), 0.1)\n",
    "            padding_value = tf.cast(padding_value, dtype=tf.float32)\n",
    "            data = tf.concat([data, padding_value], axis = 0)\n",
    "            # _input shape: [1, maxlen, embedding_units]\n",
    "            # _output shape: [1, maxlen, 1]\n",
    "            _input = tf.expand_dims(data[:, : -1], axis = 0)\n",
    "            _output = tf.expand_dims(data[:, -1 :], axis = 0)\n",
    "        if flag is not True:\n",
    "            input_tensor = tf.concat([input_tensor, _input], axis = 0)\n",
    "            output_tensor = tf.concat([output_tensor, _output], axis = 0)\n",
    "        else: \n",
    "            input_tensor = _input\n",
    "            output_tensor = _output\n",
    "            flag = False\n",
    "        \n",
    "        # 用于数据集分割，目前数据集太少了，就不分割了\n",
    "#     input_train, output_train, input_eval, output_eval = train_test_split(input_tensor, output_tensor, test_size = 0.1)\n",
    "#     return input_train, output_train, input_eval, output_eval\n",
    "    \n",
    "    return input_tensor, output_tensor,embedding_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 20\n",
    "def make_dataset(input_tensor, output_tensor, batch_size, epochs, shuffle):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((input_tensor, output_tensor))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(30000)\n",
    "        dataset = dataset.repeat(epochs).batch(batch_size, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_len: 1161\n",
      "embedding_units: 219\n"
     ]
    }
   ],
   "source": [
    "input_train, output_train, embedding_units = prase_data(dir_path)\n",
    "train_dataset = make_dataset(input_train, output_train, batch_size, epochs, True)\n",
    "print(\"embedding_units:\",embedding_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1161, 219)\n",
      "tf.Tensor([0.], shape=(1,), dtype=float32)\n",
      "(1,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for (step, (x,y)) in enumerate(train_dataset.take(1)):\n",
    "    print(x.shape)\n",
    "    z = tf.reshape(y[:, 1], (-1, ))\n",
    "    print(z)\n",
    "    print(z.shape)\n",
    "    print(step)\n",
    "#     print(x)\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_units = 256\n",
    "decoding_units = 256\n",
    "batch_size = 1\n",
    "# 判断出的分类\n",
    "classifies = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_output shape: (1, 1161, 256)\n",
      "sample_hidden shape: (1, 256)\n"
     ]
    }
   ],
   "source": [
    "class Encoder(keras.Model):\n",
    "    def __init__(self, batch_size, encoding_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.encoding_units = encoding_units\n",
    "        self.gru = keras.layers.GRU(self.encoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, inputs, hidden):\n",
    "        x = inputs\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_size, self.encoding_units))\n",
    "    \n",
    "encoder = Encoder(batch_size, encoding_units)\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(x, sample_hidden)\n",
    "print(\"sample_output shape:\", sample_output.shape)\n",
    "print(\"sample_hidden shape:\", sample_hidden.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention_results shape: (1, 256)\n",
      "atteion_weigths shape: (1, 1161, 1)\n"
     ]
    }
   ],
   "source": [
    "class BahdanauAttention(keras.Model):\n",
    "    def __init__(self, attention_units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = keras.layers.Dense(attention_units)\n",
    "        self.W2 = keras.layers.Dense(attention_units)\n",
    "        self.V = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, decoder_hidden, encoder_outputs):\n",
    "        # decoder_hidden shape: (batch_size, encoding_units)\n",
    "        # encoder_output shape: (batch_size, length, encoding_units)\n",
    "        decoder_hidden_with_time_axis = tf.expand_dims(decoder_hidden, 1)\n",
    "        \n",
    "        # before V: (batch_size, length, attention_units)\n",
    "#         print( tf.nn.tanh(\n",
    "#                 self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)).shape)\n",
    "        # after V: (batch_size, length, 1)\n",
    "        score = self.V(\n",
    "            tf.nn.tanh(\n",
    "                self.W1(encoder_outputs) + self.W2(decoder_hidden_with_time_axis)))\n",
    "        \n",
    "        # shape: (batch_size, length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis = 1)\n",
    "        \n",
    "        # shape: (batch_size, length, encoding_units)\n",
    "        context_vector = attention_weights * encoder_outputs\n",
    "        \n",
    "        # shape: (batch_size, encoding_units)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "attention_model = BahdanauAttention(10)\n",
    "attention_results, attention_weights = attention_model(sample_hidden, sample_output)\n",
    "print(\"attention_results shape:\", attention_results.shape)\n",
    "print(\"atteion_weigths shape:\", attention_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder_output shape: (1, 2)\n",
      "decoder_hidden shape: (1, 256)\n",
      "decoder_attention_weights shape: (1, 1161, 1)\n"
     ]
    }
   ],
   "source": [
    "class Decoder(keras.Model):\n",
    "    def __init__(self, classifies, decoding_units, batch_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.decoding_units = decoding_units\n",
    "        self.gru = keras.layers.GRU(self.decoding_units,\n",
    "                                    return_sequences=True,\n",
    "                                    return_state=True,\n",
    "                                    recurrent_initializer='glorot_uniform')\n",
    "        self.fc = keras.layers.Dense(classifies)\n",
    "        self.attention = BahdanauAttention(self.decoding_units)\n",
    "\n",
    "    def call(self, inputs, hidden, encoding_outputs):\n",
    "        # [b, 1, embedding_units]： single step decoder\n",
    "        x = tf.cast(inputs, dtype=tf.float32)\n",
    "\n",
    "        # context_vector: [b, enconding_units]\n",
    "        context_vector, attention_weights = self.attention(\n",
    "            hidden, encoding_outputs\n",
    "        )\n",
    "\n",
    "        # [b, 1, encoding_units + embedding_units]\n",
    "        combined_x = tf.concat(\n",
    "            [tf.expand_dims(context_vector, axis=1), x], axis=-1\n",
    "        )\n",
    "\n",
    "        # output shape: [b, 1, decoding_units]\n",
    "        # state shape: [b, decoding_units]\n",
    "        output, state = self.gru(combined_x)\n",
    "\n",
    "        # [b, 1, decoding_units] -> [b, decoding_units]\n",
    "        output = tf.reshape(output, shape=(-1, output.shape[2]))\n",
    "\n",
    "        # [b, classifies]\n",
    "        predictions = self.fc(output)\n",
    "\n",
    "        return predictions, state, attention_weights\n",
    "    \n",
    "decoder = Decoder(classifies, decoding_units, batch_size)\n",
    "outputs = decoder(tf.random.uniform((batch_size, 1, embedding_units)), sample_hidden, sample_output)\n",
    "\n",
    "decoder_output, decoder_hidden, decoder_aw = outputs\n",
    "\n",
    "print(\"decoder_output shape:\", decoder_output.shape)\n",
    "print(\"decoder_hidden shape:\", decoder_hidden.shape)\n",
    "print(\"decoder_attention_weights shape:\", decoder_aw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "# 这里reduction设置成none是为了将sentence中padding的部分做去除操作，先不聚合\n",
    "loss_object = keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # 以下代码用于去除padding，因为每个PCB板SI结构肯定不一样多\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0.1))\n",
    "    loss_ = loss_object(real, pred)\n",
    "#     print(loss_.shape)\n",
    "#     print(loss_)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "# loss_function(decoder_output, y[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inp, targ, encoding_hidden):\n",
    "    # inp: [b, len, embedding_units]\n",
    "    # targ: [b, len, classifies]\n",
    "    loss = 0\n",
    "    acc  = 0\n",
    "    with tf.GradientTape() as tape:\n",
    "        encoding_outputs, encoding_hidden = encoder(inp, encoding_hidden)\n",
    "        decoding_hidden = encoding_hidden\n",
    "\n",
    "        # every SI model's prediction should calculate losses\n",
    "        for t in range(0, targ.shape[1] - 1):\n",
    "            # use original inp to predict\n",
    "            decoding_input = tf.expand_dims(inp[:, t, :], axis=1)\n",
    "#             print(decoding_input.shape)\n",
    "\n",
    "            predictions, decoding_hidden, _ = decoder.call(decoding_input, decoding_hidden, encoding_outputs)\n",
    "            loss += loss_function(tf.reshape(targ[:, t],(-1,)), predictions)\n",
    "\n",
    "    batch_loss = loss / int(targ.shape[0])\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1161, 219)\n",
      "(6, 219)\n"
     ]
    }
   ],
   "source": [
    "a = input_train\n",
    "print(a.shape)\n",
    "print(a[:,1,:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss  26.3959\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4b1422b4e454>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     for (batch, (inp, targ)) in enumerate(\n\u001b[1;32m     11\u001b[0m         train_dataset.take(steps_per_epoch)):\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding_hidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         if batch % 100 == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-9e2f6cc47a26>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(inp, targ, encoding_hidden)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ExpandDimsGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegisterGradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ExpandDims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_ExpandDimsGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_ReshapeToInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/array_grad.py\u001b[0m in \u001b[0;36m_ReshapeToInput\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    623\u001b[0m         \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         message=\"Converting sparse IndexedSlices to a dense Tensor.*\")\n\u001b[0;32m--> 625\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \"\"\"\n\u001b[0;32m--> 458\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   8959\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   8960\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Shape\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8961\u001b[0;31m         name, _ctx._post_execution_callbacks, input, \"out_type\", out_type)\n\u001b[0m\u001b[1;32m   8962\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8963\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = len(input_train) // batch_size\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    encoding_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    for (batch, (inp, targ)) in enumerate(\n",
    "        train_dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, encoding_hidden)\n",
    "        total_loss += batch_loss\n",
    "#         if batch % 100 == 0:\n",
    "        print('Epoch {} Batch {} Loss {: .4f}'.format(epoch + 1, batch, batch_loss.numpy()))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
    "    \n",
    "    print('Time take for 1 epoch {} sec \\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input_data):\n",
    "    result = []\n",
    "    # attention_matrix = np.zeros()\n",
    "    # encoding_hidden = encoder.initialize_hidden_state()\n",
    "    encoding_hidden = tf.random.normal((1, encoding_units))\n",
    "    _inputs = tf.expand_dims(input_data, axis=0)\n",
    "    encoding_outputs, encoding_hidden = encoder(_inputs, encoding_hidden)\n",
    "    print(\"encoding_outputs:\", encoding_outputs.shape)\n",
    "    print(\"encoding_hidden:\", encoding_hidden.shape)\n",
    "    decoding_hidden = encoding_hidden\n",
    "    decoding_input = tf.zeros((1, 1, input_data.shape[1]))\n",
    "    print(\"decoding_input:\", decoding_input.shape)\n",
    "    for t in range(input_data.shape[0]):\n",
    "        pre, decoding_hidden, attention_weights = decoder.call(decoding_input, decoding_hidden, encoding_outputs)\n",
    "        # attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        # attention_matrix[t] =  attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(pre[0]).numpy()\n",
    "        result.append(classify.get(predicted_id))\n",
    "        decoding_input = tf.expand_dims(tf.expand_dims(input_data[t], axis=0), axis = 0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
